# -*- coding: utf-8 -*-
"""Main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/nihermann/Pokemaenner/blob/main/Main.ipynb
"""

##################################### Console #####################################
# !git clone https://github.com/nihermann/Pokemaenner.git
# %cd Pokemaenner/
# !git status
###################################################################################

# from google.colab import drive
# drive.mount('/content/drive')

# @title # Using Gan to create new Pokemon
import tensorflow as tf
from manager import GANManager
from data import DataGenerator
import gan
tf.keras.backend.set_floatx('float32')

# @title ## Data Settings
image_shape = (64, 64)  # @param
image_path = "./images/"  # @param {type:"string"}
batch_size = 32  # @param {type:"integer"}
validation_split = 0.1  # @param {type:"slider", min:0, max:0.5, step:0.1}
shuffle = True  # @param {type:"boolean"}

data = DataGenerator(
    img_path=image_path,
    batch_size=batch_size,
    img_height=image_shape[0],
    img_width=image_shape[1],
    validation_split=validation_split,
    # shuffle=shuffle
)

# @title Generator Arguments
latentspace = 100  # @param {type:"slider", min:2, max:1000, step:1}

generator = gan.Generator(
    latentspace=latentspace
)

# @title ## Discriminator Arguments
discriminator = gan.Discriminator(
    input_shape=(None, image_shape[0], image_shape[1], 3)
)

# @title ## Hyperparameters


loss_function = "Binary Cross Entropy"  # @param ["Binary Cross Entropy", "Mean Squared Error"]
optimizer = "Adam"  # @param ["Adam", "RMSprop", "SGD"]
learning_rate = 0.001  # @param {type:"number"}

## Dropdown equivalents
loss_functions = {
    "Binary Cross Entropy": tf.keras.losses.BinaryCrossentropy(),
    "Mean Squared Error": tf.keras.losses.MSE
}

optimizers = {
    "Adam": tf.keras.optimizers.Adam(learning_rate),
    "RMSprop": tf.keras.optimizers.RMSprop(learning_rate),
    "SGD": tf.keras.optimizers.SGD
}

## Final
kwargs = {
    "batch_size": batch_size,
    "loss": loss_functions[loss_function],
    "optimizer": optimizers[optimizer]
}

manager = GANManager(
    kwargs=kwargs,
    generator=generator,
    discriminator=discriminator,
    data=data
)

# @title # Training Parameters
epochs = 100  # @param {type:"integer"}
samples_per_epoch = 10000  # @param {type:"integer"}
trainings_frequency = (5, 5)  # @param {type:"raw"}
print_every = 1  # @param {type:"integer"}
print_verbose = True  # @param {type:"boolean"}
save_pictures_every = 1  # @param {type:"integer"}
how_many_pictures_to_save = 2  # @param {type:"integer"}
pictures_save_path = "./pictures/"  # @param {type:"string"}
save_model_every = 0  # @param {type:"integer"}

manager.train(
    epochs=epochs,
    samples_per_epoch=samples_per_epoch,
    trainings_frequency=trainings_frequency,
    print_every=print_every,
    print_verbose=print_verbose,
    save_pictures_every=save_pictures_every,
    how_many_pictures_to_save=how_many_pictures_to_save,
    pictures_save_path=pictures_save_path,
    save_model_every=save_model_every
)
