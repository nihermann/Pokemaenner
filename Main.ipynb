{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nihermann/Pokemaenner/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcOo6FsZQBeU"
      },
      "source": [
        "##################################### Console #####################################\n",
        "# !git clone https://github.com/nihermann/Pokemaenner.git\n",
        "# %cd Pokemaenner/\n",
        "# !git status\n",
        "###################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L330oGEvHYgF",
        "outputId": "d9a3faf0-9240-4adb-f9a5-acd8259d99c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GRx2L6zBX2X",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "source": [
        "#@title # Using Gan to create new Pokemon\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from data import DataGenerator\n",
        "import gan\n",
        "from aegan import (AEGAN, SaveAeganPictures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQwvLIGLiSKf",
        "cellView": "form"
      },
      "source": [
        "#@title # Model\n",
        "#@markdown ## AEGAN\n",
        "use_aegan = True #@param {type:\"boolean\"}\n",
        "if use_aegan:\n",
        "    image_shape = (64,64) #@param\n",
        "    latentspace =  16#@param {type:\"integer\"}\n",
        "    batch_size = 32 #@param {type:\"integer\"}\n",
        "    noise_generating_function =  lambda b: tf.normal((b, latentspace))#@param {type:\"raw\"}\n",
        "    continue_from_saved_models = False #@param {type:\"boolean\"}\n",
        "    path = \"./outputs/models\" #@param [\"./models\"] {allow-input: true}\n",
        "\n",
        "    batch_size *= 8\n",
        "\n",
        "    model = AEGAN(\n",
        "        image_shape=image_shape,\n",
        "        latentspace=latentspace,\n",
        "        batch_size=batch_size,\n",
        "        noise_generating_fn=noise_generating_function,\n",
        "        continue_from_saved_models=continue_from_saved_models,\n",
        "        path=path,\n",
        "    )\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzkufT1iBke_",
        "cellView": "form",
        "outputId": "324f849d-5ddb-436b-ab56-99443650848a"
      },
      "source": [
        "#@title ## Data Settings\n",
        "\n",
        "image_path = \"/content/drive/MyDrive/images/\" #@param {type:\"string\"}\n",
        "images_in_test_split = 20 #@param {type:\"slider\", min:4, max:20, step:4}\n",
        "horizontal_flip = False #@param {type:\"boolean\"}\n",
        "shuffle = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "data = DataGenerator(\n",
        "    img_path=image_path,\n",
        "    batch_size=batch_size,\n",
        "    img_size=image_shape,\n",
        "    validation_split=images_in_test_split,\n",
        "    horizontal_flip=horizontal_flip,\n",
        "    shuffle=shuffle\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10135 files belonging to 14 classes.\n",
            "Using 9122 files for training.\n",
            "Found 10135 files belonging to 14 classes.\n",
            "Using 1013 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peB1T2J6BX2Y",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# #@title ## Hyperparameters\n",
        "\n",
        "\n",
        "# loss_function = \"Binary Cross Entropy\" #@param [\"Binary Cross Entropy\", \"Mean Squared Error\"]\n",
        "# optimizer = \"Adam\" #@param [\"Adam\", \"RMSprop\", \"SGD\"]\n",
        "# learning_rate = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "# ## Dropdown equivalents\n",
        "# loss_functions = {\n",
        "#     \"Binary Cross Entropy\": tf.keras.losses.BinaryCrossentropy(),\n",
        "#     \"Mean Squared Error\": tf.keras.losses.MSE\n",
        "# }\n",
        "\n",
        "# optimizers = {\n",
        "#     \"Adam\": tf.keras.optimizers.Adam(learning_rate),\n",
        "#     \"RMSprop\": tf.keras.optimizers.RMSprop(learning_rate),\n",
        "#     \"SGD\": tf.keras.optimizers.SGD\n",
        "# }\n",
        "\n",
        "\n",
        "# ## Final\n",
        "# kwargs = {\n",
        "#     \"batch_size\": batch_size,\n",
        "#     \"loss\": loss_functions[loss_function],\n",
        "#     \"optimizer\": optimizers[optimizer]\n",
        "# }\n",
        "\n",
        "# manager = GANManager(\n",
        "#     kwargs=kwargs,\n",
        "#     generator=generator,\n",
        "#     discriminator=discriminator,\n",
        "#     data=data\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TXQNUflBa2u",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "source": [
        "#@title # Training Parameters\n",
        "epochs = 2 #@param {type:\"integer\"}\n",
        "samples_per_epoch = 5 #@param {type:\"integer\"}\n",
        "print_verbose = \"progressbar\" #@param [\"no_prints\", \"print_after_each_epoch\", \"progressbar\"]\n",
        "print_verbose = {\"no_prints\": 0, \"print_after_each_epoch\": 2, \"progressbar\": 1}[print_verbose]\n",
        "\n",
        "#@markdown ## Callbacks\n",
        "#@markdown ### Model saving\n",
        "callbacks = []\n",
        "save_models = False #@param {type:\"boolean\"}\n",
        "if save_models:\n",
        "    model_path = \"./outputs/models/aegan{epoch:03d}.h5\" #@param [\"./outputs/models/\"] {allow-input: true}\n",
        "\n",
        "    callbacks.append(\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=model_path,\n",
        "            save_weights_only=save_weights_only,\n",
        "        )\n",
        "    )\n",
        "\n",
        "#@markdown ### Tensorboard\n",
        "use_tensorboard = False #@param {type:\"boolean\"}\n",
        "log_dir = None\n",
        "if use_tensorboard:\n",
        "    log_dir = \"./logs/images\" #@param [\"./logs\"] {allow-input: true}\n",
        "    update_frequency = \"epoch\" #@param [\"batch\", \"epoch\"] {allow-input: true}\n",
        "\n",
        "    timestemp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    log_dir += ('' if log_dir.endswith('/') else '/') + timestemp\n",
        "\n",
        "    print(f\"TensorBoard logdir: {log_dir}\")\n",
        "\n",
        "    callbacks.append(\n",
        "        tf.keras.callbacks.TensorBoard(\n",
        "            log_dir=log_dir,\n",
        "            update_freq=update_frequency\n",
        "        )\n",
        "    )\n",
        "\n",
        "    def launchTensorBoard():\n",
        "        import os\n",
        "        os.system('tensorboard --logdir=' + log_dir)\n",
        "        return\n",
        "\n",
        "    import threading\n",
        "\n",
        "    t = threading.Thread(target=launchTensorBoard, args=([]))\n",
        "    t.start()\n",
        "\n",
        "#@markdown ### Save Pictures and Images for AEGAN\n",
        "#@markdown Images will be saved to file and displayed in tensorboard if activated.\n",
        "#@markdown The number of images equals to the amount of pictrures specified in the validation data split.\n",
        "save_pictures = True #@param {type:\"boolean\"}\n",
        "if save_pictures:\n",
        "    pictures_path = \"./outputs/\" #@param [\"./output/\"] {allow-input: true}\n",
        "    save_pictures_every = 2 #@param {type:\"integer\"}\n",
        "    save_model_every = 3 #@param {type:\"integer\"}\n",
        "\n",
        "    callbacks.append(\n",
        "        SaveAegan(\n",
        "            save_images_every=save_pictures_every,\n",
        "            save_model_every=save_model_every,\n",
        "            save_path=pictures_path,\n",
        "            data_gen=data.validation_generator,\n",
        "            tensorboard_logdir=log_dir\n",
        "        )\n",
        "    )\n",
        "\n",
        "assert model is not None, \"Model must not be None, please make sure to enable one of them by setting the respective bool to True!\"\n",
        "# model = tf.keras.models.load_model(\"./outputs/models\")\n",
        "print(\"Start training..\")\n",
        "model.fit(\n",
        "    x=data.training_generator,\n",
        "    steps_per_epoch=samples_per_epoch,\n",
        "    epochs=epochs + model.initial_epoch,\n",
        "    verbose=print_verbose,\n",
        "    callbacks=callbacks,\n",
        "    initial_epoch=model.initial_epoch\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}